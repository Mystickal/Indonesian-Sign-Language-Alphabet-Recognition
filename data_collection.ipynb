{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # system functions (ie. exiting the program)\n",
    "import os # operating system functions (ie. path building on Windows vs. MacOs)\n",
    "import time # for time operations\n",
    "import uuid # for generating unique file names\n",
    "import math # math functions\n",
    "\n",
    "from IPython.display import display as ipydisplay, Image, clear_output, HTML # for interacting with the notebook better\n",
    "\n",
    "import numpy as np # matrix operations (ie. difference between two matricies)\n",
    "import cv2 # (OpenCV) computer vision functions (ie. tracking)\n",
    "\n",
    "import matplotlib.pyplot as plt # (optional) for plotting and showing images inline\n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "\n",
    "import keras # high level api to tensorflow (or theano, CNTK, etc.) and useful image preprocessing\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predefined Pathing to save the model and training history\n",
    "\n",
    "DATA_FOLDER = os.path.join('images')\n",
    "MODEL_PATH = os.path.join('model')\n",
    "MODEL_FILE = os.path.join(MODEL_PATH, 'hand_recog_model.hdf5')\n",
    "MODEL_HISTORY = os.path.join(MODEL_PATH, 'model_history.txt')\n",
    "OUTPUT_TEXT = os.path.join('output', 'outputtext.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tracker.\n",
    "def setup_tracker(ttype):\n",
    "    tracker_types = {\n",
    "        'KCF': cv2.TrackerBoosting_create,\n",
    "        'MEDIANFLOW': cv2.TrackerMedianFlow_create,\n",
    "        'CSRT': cv2.TrackerCSRT_create,\n",
    "        'MOSSE': cv2.TrackerMOSSE_create\n",
    "    }\n",
    "    tracker = tracker_types[ttype]()\n",
    "    return tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for Data Collection\n",
    "classes = {\n",
    "    0: 'A',\n",
    "    1: 'B',\n",
    "    2: 'C',\n",
    "    3: 'D',\n",
    "    4: 'E',\n",
    "    5: 'F',\n",
    "    6: 'G',\n",
    "    7: 'H',\n",
    "    8: 'I',\n",
    "}\n",
    "\n",
    "#Modify Storage Paths, images will be saved in the following path: DATA/POSE\n",
    "POSE = 'I'\n",
    "#DATA = os.path.join('training_data')\n",
    "DATA = os.path.join('validation_data')\n",
    "\n",
    "# Begin video cpature\n",
    "video = cv2.VideoCapture(0)\n",
    "if not video.isOpened():\n",
    "    print(\"ERROR: Could not open webcam\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# Read first frame\n",
    "success, frame = video.read()\n",
    "if not success:\n",
    "    print(\"ERROR: Cannot read video\")\n",
    "    sys.exit()\n",
    "# Use the first frame as an initial background frame\n",
    "bg = frame.copy()\n",
    "\n",
    "\n",
    "# Kernel for image processing\n",
    "kernel = np.ones((2,2),np.uint8)\n",
    "\n",
    "\n",
    "# Initialize Tracker's Position\n",
    "# Bounding box -> (TopRightX, TopRightY, Width, Height)\n",
    "bbox_initial = (60, 60, 170, 170)\n",
    "bbox = bbox_initial\n",
    "# Tracking status, -1 for not tracking, 0 for unsuccessful tracking, 1 for successful tracking\n",
    "tracking = -1\n",
    "\n",
    "\n",
    "# Text display positions\n",
    "positions = {\n",
    "    'hand_pose': (15, 40),\n",
    "    'fps': (15, 20)\n",
    "}\n",
    "\n",
    "\n",
    "# Image counter for convinience with naming dataset\n",
    "img_count = 0\n",
    "\n",
    "# Begin video loop\n",
    "while True:\n",
    "    # Read a new frame\n",
    "    success, frame = video.read()\n",
    "    display = frame.copy()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "        \n",
    "    #To limit and keep image datasets amount similar\n",
    "    if img_count > 50:\n",
    "        break\n",
    "        \n",
    "    # Start timer\n",
    "    timer = cv2.getTickCount()\n",
    "\n",
    "    # Process video feed from the webcam to be used for training/validation sets later\n",
    "    \n",
    "    # Get absolute difference between first frame (background) and current frame (frame)\n",
    "    diff = cv2.absdiff(bg, frame)\n",
    "    mask = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Morphological Transformation applied to the mask\n",
    "    gradient = cv2.morphologyEx(mask, cv2.MORPH_GRADIENT, kernel)\n",
    "    \n",
    "    # Threshold applied to add more defining outline\n",
    "    th, thresh = cv2.threshold(gradient, 10, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # If tracking is active, update the tracker\n",
    "    if tracking != -1:\n",
    "        tracking, bbox = tracker.update(foreground)\n",
    "        tracking = int(tracking)\n",
    "        \n",
    "        \n",
    "    # Use numpy array indexing to crop the foreground frame\n",
    "    hand_crop = thresh[int(bbox[1]):int(bbox[1]+bbox[3]), int(bbox[0]):int(bbox[0]+bbox[2])]\n",
    "    \n",
    "        \n",
    "    # Draw bounding box\n",
    "    p1 = (int(bbox[0]), int(bbox[1]))\n",
    "    p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "    cv2.rectangle(thresh, p1, p2, (255, 0, 0), 2, 1)\n",
    "    cv2.rectangle(display, p1, p2, (255, 0, 0), 2, 1)\n",
    "    \n",
    "        \n",
    "    # Calculate Frames per second (FPS)\n",
    "    fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer)\n",
    "    # Display FPS on frame\n",
    "    cv2.putText(thresh, \"FPS : \" + str(int(fps)), positions['fps'], cv2.FONT_HERSHEY_SIMPLEX, 0.65, (50, 170, 50), 2)\n",
    "    cv2.putText(display, \"FPS : \" + str(int(fps)), positions['fps'], cv2.FONT_HERSHEY_SIMPLEX, 0.65, (50, 170, 50), 2)\n",
    "    cv2.putText(display, \"hand pose: {}\".format(POSE), positions['hand_pose'], cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "    cv2.putText(gradient, \"hand pose: {}\".format(POSE), positions['hand_pose'], cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "    \n",
    "    # Display result\n",
    "    cv2.imshow(\"display\", display)\n",
    "    # Display diff\n",
    "    cv2.imshow(\"diff\", diff)\n",
    "    # Display thresh\n",
    "    cv2.imshow(\"thresh\", thresh)\n",
    "    \n",
    "    try:\n",
    "        # Display hand_crop\n",
    "        cv2.imshow(\"hand_crop\", hand_crop)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    \n",
    "    if k == 27: break # ESC pressed then stop recording\n",
    "    elif k == 114 or k == 82: \n",
    "        # Press R to restart the video and bounding box\n",
    "        bg = frame.copy()\n",
    "        bbox = bbox_initial\n",
    "        tracking = -1\n",
    "    elif k == 84:\n",
    "        # T pressed\n",
    "        # Initialize tracker in first frame and bounding box\n",
    "        tracker = setup_tracker('MEDIANFLOW')\n",
    "        tracking = tracker.init(frame, bbox)\n",
    "    elif k == 115 or k == 83:\n",
    "        # s pressed then save images to the folder\n",
    "        img_count += 1\n",
    "        DATA_FOLDER = os.path.join(\"DATA\")\n",
    "        fname = os.path.join(DATA, POSE, \"{}_{}.jpg\".format(POSE, img_count))\n",
    "        status = cv2.imwrite(fname, hand_crop)\n",
    "        if status is True:\n",
    "            print(\"Image saved!\")\n",
    "        else:\n",
    "            print(\"There was an error in saving the image\")\n",
    "    elif k != 255: print(k)\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
